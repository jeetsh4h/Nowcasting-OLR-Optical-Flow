{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7329e08",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24dce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# from moviepy.editor import ImageSequenceClip\n",
    "# from moviepy.video.io.bindings import mplfig_to_npimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c9bae",
   "metadata": {},
   "source": [
    "# Processing Satellite Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c1dfd",
   "metadata": {},
   "source": [
    "Windowed data across all three years  \n",
    "Using 2020 for training and 2021 for testing  \n",
    "Using 2022 for validation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e11b30",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66add8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_by_date(\n",
    "    start_datetime, end_datetime,\n",
    "    root_path, fn_pattern, fn_ext,\n",
    "    timestep, error=1,\n",
    "    upper=True, lower=False, verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    start_datetime -> must be in the datetime format (inclusive of time)  \n",
    "    end_datetime   -> must be in the datetime format (inclusive of time)  \n",
    "    root_path      -> the path to the folder where all the files are stored  \n",
    "    fn_pattern     -> the general name of the file with the datetime pattern (strformat) embedded  \n",
    "    fn_ext         -> extension of the file, do NOT include the '.'  \n",
    "    timestep       -> in minutes,,, the time difference between two consecutive files  \n",
    "    error          -> in minutes,,, if the files are not exactly in a regular timestep, add the usual error (2 means +1, +2 min AND -1, -2 min)  \n",
    "    upper          -> convert the filename into upper case (some stupid thing with format)  \n",
    "    lower          -> convert the filename into lower case (added because just upper was weird)  \n",
    "    verbose        -> prints all the files not found  \n",
    "    \n",
    "    **note** -> defaults are set up to work with satellite data from MOSDAC\n",
    "    \"\"\"\n",
    "\n",
    "# error handling\n",
    "    if upper and lower:\n",
    "        raise ValueError(\"Cannot have both arguments, 'upper' and 'lower' be True!\")\n",
    "\n",
    "    if timestep <= 0 or isinstance(timestep, float):\n",
    "        raise ValueError(\"Argument 'timestep' can only be a positive integer\")\n",
    "\n",
    "    if not (isinstance(start_datetime, datetime) and isinstance(end_datetime, datetime)):\n",
    "        raise TypeError(\"Both 'start_datetime', 'end_datetime' arguments must be datetime objects\")\n",
    "\n",
    "    if not os.path.exists(root_path):\n",
    "        raise IOError(\"Path provided in the 'root_path' argument does not exist\")\n",
    "\n",
    "    filenames = []\n",
    "    timestamps = []\n",
    "\n",
    "    cur_datetime = start_datetime\n",
    "\n",
    "    while cur_datetime <= end_datetime + timedelta(minutes=error):\n",
    "        fn = _find_matching_fn(\n",
    "            cur_datetime, root_path, fn_pattern, fn_ext, error,\n",
    "            upper, lower, verbose\n",
    "        )\n",
    "\n",
    "        filenames.append(fn)\n",
    "        timestamps.append(cur_datetime)\n",
    "\n",
    "    # iterating through the datetimes\n",
    "        cur_datetime = cur_datetime + timedelta(minutes=timestep)\n",
    "\n",
    "# this error exists because verbose might be false\n",
    "    if all(filename is None for filename in filenames):\n",
    "        raise IOError(f\"No input data found in {root_path} with the given datetime range\")\n",
    "\n",
    "    return filenames, timestamps\n",
    "\n",
    "\n",
    "def _find_matching_fn(\n",
    "    cur_datetime, root_path, fn_pattern, fn_ext, error,\n",
    "    upper, lower, verbose\n",
    "):\n",
    "    \n",
    "# without error (timestep)    \n",
    "    fn = _gen_fn_path(\n",
    "        cur_datetime,\n",
    "        root_path, fn_pattern, fn_ext,\n",
    "        upper, lower\n",
    "    )\n",
    "\n",
    "    if os.path.exists(fn):\n",
    "        return fn\n",
    "\n",
    "# with negative error\n",
    "    for i in range(1, error+1):\n",
    "        fn = _gen_fn_path(\n",
    "            cur_datetime - timedelta(minutes=i),\n",
    "            root_path, fn_pattern, fn_ext,\n",
    "            upper, lower\n",
    "        )\n",
    "        if os.path.exists(fn):\n",
    "            return fn\n",
    "    \n",
    "# with positive error\n",
    "    for i in range(1, error+1):\n",
    "        fn = _gen_fn_path(\n",
    "            cur_datetime + timedelta(minutes=i),\n",
    "            root_path, fn_pattern, fn_ext,\n",
    "            upper, lower\n",
    "        )\n",
    "        if os.path.exists(fn):\n",
    "            return fn\n",
    "\n",
    "# nothing matched\n",
    "    if verbose:\n",
    "        error_date = datetime.strftime(cur_datetime, fn_pattern)\n",
    "        if upper:\n",
    "            error_date = error_date.upper()\n",
    "        if lower:\n",
    "            error_date = error_date.lower()\n",
    "            \n",
    "        print(f\"file not found with datetime: {error_date}\")\n",
    "    \n",
    "    return None            \n",
    "\n",
    " \n",
    "def _gen_fn_path(\n",
    "    cur_datetime, root_path, fn_pattern, fn_ext, \n",
    "    upper, lower\n",
    "):\n",
    "    fn = datetime.strftime(cur_datetime, fn_pattern)\n",
    "        \n",
    "    if upper:\n",
    "        fn = fn.upper()\n",
    "    if lower:\n",
    "        fn = fn.lower()\n",
    "            \n",
    "    fn = fn + '.' + fn_ext\n",
    "    fn = os.path.join(root_path, fn)\n",
    "        \n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0dff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5ToNumpyMatrix(file_path):\n",
    "# 512, 512 is image size I am planning working with (that didnt pan out huh),, padding to maintain size ##\n",
    "    if file_path is None:\n",
    "        return np.zeros((400, 400))\n",
    "\n",
    "# in case I have introduced a bug in the previous functions\n",
    "    if not os.path.exists(file_path):\n",
    "        raise IOError(f\"File {file_path} not found\")\n",
    "\n",
    "# extracting information\n",
    "    cur_file = h5py.File(file_path)\n",
    "    \n",
    "    lat = cur_file['Latitude'][()] * 0.01\n",
    "    lon = cur_file['Longitude'][()] * 0.01\n",
    "    \n",
    "    olr = np.squeeze(cur_file['OLR'][()])\n",
    "\n",
    "# Filter data within location of interest  \n",
    "    lat_filtered = lat[(lat >= 0) & (lat < 40) & (lon >= 60) & (lon < 100)]\n",
    "    lon_filtered = lon[(lat >= 0) & (lat < 40) & (lon >= 60) & (lon < 100)]\n",
    "    olr_filtered = olr[(lat >= 0) & (lat < 40) & (lon >= 60) & (lon < 100)]\n",
    "\n",
    "# Grid data from 0-40N Latitude, 60-100E Longitude with 0.1 deg resolution\n",
    "    olr_grid = np.zeros((400, 400))\n",
    "    cnt = np.zeros((400, 400))\n",
    "\n",
    "# Generating index values\n",
    "    lat_ind = np.int32((lat_filtered - 0) * 10)\n",
    "    lon_ind = np.int32((lon_filtered - 60) * 10)\n",
    "    \n",
    "    np.add.at(olr_grid, (lat_ind, lon_ind), olr_filtered)\n",
    "    np.add.at(cnt, (lat_ind, lon_ind), 1)\n",
    "\n",
    "    olr_grid[cnt > 0] = olr_grid[cnt > 0] / cnt[cnt > 0]  \n",
    "    olr_grid[cnt == 0] = np.nan\n",
    "    \n",
    "## padding (might change,, if you do change at the top) ##\n",
    "#     olr_grid = np.pad(olr_grid, ((56, 56), (56, 56)), mode='constant', constant_values=np.nan)\n",
    "    \n",
    "    return olr_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1ee964",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make changes to the paths HERE if you want to use it to suit your needs ###\n",
    "def process_by_year(year: int):\n",
    "# looping through the folder as per datetime\n",
    "    olr_load = {\n",
    "        'start_datetime': datetime(year, 5, 1, 0, 0),\n",
    "        'end_datetime': datetime(year, 9, 30, 23, 30),\n",
    "        'root_path': f'./data/May-Sep{year}',\n",
    "        'fn_pattern': '3DIMG_%d%b%Y_%H%M_L2B_OLR_V01R00',\n",
    "        'fn_ext': 'h5',\n",
    "        'timestep': 30,\n",
    "    }\n",
    "    filenames, timestamps = find_by_date(**olr_load)\n",
    "\n",
    "# extracting olr data from the h5 files,,, error handling for no file existing for that time\n",
    "    all_olr_grids = [h5ToNumpyMatrix(fn) for fn in filenames]\n",
    "\n",
    "# ultility to handle the empty files\n",
    "    window_start_indices = [idx for idx in range(len(filenames) - 12) if not None in filenames[idx:idx+12]]\n",
    "\n",
    "# data windowing\n",
    "    X_y = [all_olr_grids[start_idx:start_idx+12] for start_idx in window_start_indices]\n",
    "\n",
    "# saving all the data windows into disk\n",
    "    save_path = f'./data/processed_May-Sep{year}/'\n",
    "    save_pattern = '%d%b%Y_%H%M_L2B_OLR'\n",
    "    ### the filename corresponding to each data window states the datetime at which the data window starts (X starts) ###\n",
    "    for i in range(len(X_y)):\n",
    "        np.save((save_path + datetime.strftime(timestamps[window_start_indices[i]], save_pattern)), X_y[i], allow_pickle=False, fix_imports=False)\n",
    "\n",
    "##### while loading the npy files using the find_by_date thing, make **upper=False** #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b5ee6",
   "metadata": {},
   "source": [
    "## Processing Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c643050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done\n",
    "process_by_year(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97a1dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done\n",
    "process_by_year(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196bc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done\n",
    "process_by_year(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07325c88",
   "metadata": {},
   "source": [
    "# Further Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcb771",
   "metadata": {},
   "source": [
    "This is me trying to decrease the size of the input data to be able to use it through google colab  \n",
    "Will probably merge 2020 and 2021 for training and use 2022 testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c574d",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4177f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses utility functions from the processing raw data\n",
    "def find_by_date_further(\n",
    "    start_datetime, end_datetime,\n",
    "    root_path, fn_pattern, fn_ext,\n",
    "    timestep, error=1,\n",
    "    upper=False, lower=False, verbose=False\n",
    "):\n",
    "    \"\"\"further_process_by_year(2020)\n",
    "    same docstring as the function find_by_date\n",
    "    \"\"\"\n",
    "\n",
    "    # error handling\n",
    "    if upper and lower:\n",
    "        raise ValueError(\"Cannot have both arguments, 'upper' and 'lower' be True!\")\n",
    "\n",
    "    if timestep <= 0 or isinstance(timestep, float):\n",
    "        raise ValueError(\"Argument 'timestep' can only be a positive integer\")\n",
    "\n",
    "    if not (isinstance(start_datetime, datetime) and isinstance(end_datetime, datetime)):\n",
    "        raise TypeError(\"Both 'start_datetime', 'end_datetime' arguments must be datetime objects\")\n",
    "\n",
    "    if not os.path.exists(root_path):\n",
    "        raise IOError(\"Path provided in the 'root_path' argument does not exist\")\n",
    "\n",
    "    filenames = []\n",
    "    timestamps = []\n",
    "\n",
    "    cur_datetime = start_datetime\n",
    "# the main changes are in the loop\n",
    "    while cur_datetime <= end_datetime + timedelta(minutes=error):\n",
    "        fn = _find_matching_fn(\n",
    "            cur_datetime, root_path, fn_pattern, fn_ext, error,\n",
    "            upper, lower, verbose\n",
    "        )\n",
    "\n",
    "        if fn == None:\n",
    "            cur_datetime += timedelta(minutes=timestep)\n",
    "            continue\n",
    "\n",
    "        filenames.append(fn)\n",
    "        timestamps.append(cur_datetime)\n",
    "    \n",
    "    # 12 is used because there are 12 datapoints in the window, this number is selected for this particular use case\n",
    "    # should probably make it a parameter\n",
    "        cur_datetime += timedelta(minutes=timestep*12)\n",
    "\n",
    "# this error exists for verbose equals false\n",
    "    if all(filename is None for filename in filenames):\n",
    "        raise IOError(f\"No input data found in {root_path} with the given datetime range\")\n",
    "\n",
    "    return filenames, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9487e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make changes to the paths HERE if you want to use it to suit your needs ###\n",
    "def further_process_by_year(year: int):\n",
    "# looping through processed folder such that all data windows have no overlapping frames\n",
    "    further_process_params = {\n",
    "        'start_datetime': datetime(year, 5, 1, 0, 0),\n",
    "        'end_datetime': datetime(year, 9, 30, 23, 30),\n",
    "        'root_path': f'./data/processed_May-Sep{year}',\n",
    "        'fn_pattern': '%d%b%Y_%H%M_L2B_OLR',\n",
    "        'fn_ext': 'npy',\n",
    "        'timestep': 30,\n",
    "    }\n",
    "    _, timestamps = find_by_date_further(**further_process_params)\n",
    "\n",
    "# copy pasting the found files into new folder \n",
    "    source_path = further_process_params['root_path'] + '/'\n",
    "    target_path = f'./data/further_processed_May-Sep{year}/'\n",
    "    \n",
    "    for ts in timestamps:\n",
    "        fn_rebuilt = datetime.strftime(ts, further_process_params['fn_pattern']) + '.' + further_process_params['fn_ext']\n",
    "        shutil.copyfile(source_path + fn_rebuilt, target_path + fn_rebuilt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde1149",
   "metadata": {},
   "source": [
    "## Processing for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done\n",
    "further_process_by_year(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done\n",
    "further_process_by_year(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53084fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done\n",
    "further_process_by_year(2022)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f7c2ebcc90e09e098736dc7ef0cfa24f4a25255fc31a4184c026a8bdedb56eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
